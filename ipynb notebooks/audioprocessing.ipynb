{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdx2CC1mdJjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b36060-a9d9-490d-e791-d7d2740fb108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting subprocess.run\n",
            "  Downloading subprocess.run-0.0.8.tar.gz (4.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: subprocess.run\n",
            "  Building wheel for subprocess.run (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess.run: filename=subprocess.run-0.0.8-py3-none-any.whl size=5337 sha256=1a799aadd9c46a35e4ed7460fecb87db5e17ffe669ad0b3f8dc8ceeb93f0881f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/5e/b6/33edc01d69e6253dc545cfc1a260f75a9b81afc14a0291592f\n",
            "Successfully built subprocess.run\n",
            "Installing collected packages: subprocess.run\n",
            "Successfully installed subprocess.run-0.0.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install subprocess.run\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import shutil\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import shutil\n",
        "from pydub import AudioSegment\n",
        "import pickle"
      ],
      "metadata": {
        "id": "4ui8Ej9CHy-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/IP/video_train_test\"\n",
        "path1 = \"/content/drive/MyDrive/IP/audio_train_test\""
      ],
      "metadata": {
        "id": "v7WTmGA4dcVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting video to audio\n",
        "k=0\n",
        "entries=os.listdir(path)\n",
        "for entry in entries:\n",
        "  print(entry+\"\\t\")\n",
        "  for pfolders in os.listdir(path+'/'+entry+'/'):\n",
        "    print(pfolders+\" \")\n",
        "    for file_name in os.listdir(path+'/'+entry+'/'+pfolders+'/'):\n",
        "      mp4_file = path+'/'+entry+'/'+pfolders+'/'+file_name\n",
        "      print(mp4_file)\n",
        "      wav_file = path1+'/'+entry+'/'+pfolders+'/'+file_name.split(\".mp4\")[0]+'.wav'\n",
        "      if not os.path.isdir(path1+'/'+entry+'/'+pfolders+'/'):\n",
        "        os.makedirs(path1+'/'+entry+'/'+pfolders+'/')\n",
        "\n",
        "      audio = AudioSegment.from_file(mp4_file, format=\"mp4\")\n",
        "      # # export the audio as WAV\n",
        "      audio.export(wav_file, format=\"wav\")\n",
        "      # print(file_name)\n"
      ],
      "metadata": {
        "id": "FSNL6fnfdfPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input file path\n",
        "mp4_file = f\"/content/drive/MyDrive/IP/video_train_test/test/neuroticism/5uFZ-2kYGO0.000.mp4\"\n",
        "\n",
        "# output file path\n",
        "wav_file = \"/content/drive/MyDrive/IP/audio_train_test/djfkdh.wav\"\n",
        "\n",
        "# load the MP4 file\n",
        "audio = AudioSegment.from_file(mp4_file, format=\"mp4\")\n",
        "\n",
        "# export the audio as WAV\n",
        "audio.export(wav_file, format=\"wav\")"
      ],
      "metadata": {
        "id": "UmWHBxE9dpOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "drDJw3UpsZlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/audio_train_test'\n",
        "path1 = '/content/drive/MyDrive/spectograpgh_train_test'\n",
        "\n",
        "if not os.path.exists(path1):\n",
        "    os.makedirs(path1)"
      ],
      "metadata": {
        "id": "L5zLRFNJ16Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating spectrograph from audio file (Dont RUN)\n",
        "count=0\n",
        "for validation in os.listdir(path):\n",
        "  print(\"valid\",validation)\n",
        "  if not os.path.exists(path1+'/'+validation):\n",
        "    os.makedirs(path1+'/'+validation)\n",
        "  for cat in os.listdir(path+'/'+validation+'/'):\n",
        "    if not os.path.exists(path1+'/'+validation+'/'+cat):\n",
        "      os.makedirs(path1+'/'+validation+'/'+cat)\n",
        "    # print(\"cat\",cat)\n",
        "    k=1\n",
        "    for file in os.listdir(path+'/'+validation+'/'+cat):\n",
        "      if k==30 and validation == \"train\":\n",
        "        break\n",
        "      if k==8 and validation ==\"test\":\n",
        "        break\n",
        "      # print(\"file\",file)\n",
        "      if not os.path.exists(path1+'/'+validation+'/'+cat):\n",
        "        os.makedirs(path1+'/'+validation+'/'+cat)\n",
        "      # print(f'{path}/{validation}/{cat}/{file}')\n",
        "      signal, sr = librosa.load(f'{path}/{validation}/{cat}/{file}', sr=22050)\n",
        "      size = signal.shape[0]\n",
        "      start = 0\n",
        "      end = start + (size//5) #dividing the sound into 5 parts for more accuracy\n",
        "      for i in range(5):\n",
        "        if f'{file[:-4] +\"_\"+ str(i)}.png' not in os.listdir(path1+'/'+validation+'/'+cat):\n",
        "          part_of_signal = signal[start:end]\n",
        "          mfcc = librosa.feature.mfcc(y=part_of_signal,\n",
        "                      n_fft=2048,\n",
        "                      hop_length=512,\n",
        "                      n_mfcc=13)\n",
        "          librosa.display.specshow(mfcc, sr=sr, hop_length=512)\n",
        "          plt.savefig(f'{path1}/{validation}/{cat}/{file[:-4] +\"_\"+ str(i)}.png')\n",
        "        else:\n",
        "          print(\"Already Present \",count)\n",
        "          count+=1\n",
        "        start = end\n",
        "        end = start + (size//5)\n",
        "      k+=1\n",
        "      print(k)\n",
        ""
      ],
      "metadata": {
        "id": "YVzXWq_OsdKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"/content/drive/MyDrive/audio_train_test/train\"\n",
        "\n",
        "for cat in os.listdir(directory):\n",
        "  # print(cat)\n",
        "  num_files = 0\n",
        "  files = os.listdir(directory+'/'+cat)\n",
        "  print(cat,\" : \",len(files))"
      ],
      "metadata": {
        "id": "Txh4w8vlckGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178c99b6-68e3-43ac-d835-ed404882c46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraversion  :  39\n",
            "conscientiousness  :  184\n",
            "neuroticism  :  81\n",
            "agreeableness  :  194\n",
            "openness  :  186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"/content/drive/MyDrive/audio_train_test/test\"\n",
        "\n",
        "for cat in os.listdir(directory):\n",
        "  # print(cat)\n",
        "  num_files = 0\n",
        "  files = os.listdir(directory+'/'+cat)\n",
        "  print(cat,\" : \",len(files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRMi-na5ngC",
        "outputId": "46b34e84-817b-4935-e60d-846701d34928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neuroticism  :  21\n",
            "agreeableness  :  49\n",
            "extraversion  :  10\n",
            "conscientiousness  :  46\n",
            "openness  :  68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = path1+\"/test\"\n",
        "\n",
        "for cat in os.listdir(directory):\n",
        "  # print(cat)\n",
        "  num_files = 0\n",
        "  files = os.listdir(directory+'/'+cat)\n",
        "  print(cat,\" : \",len(files))"
      ],
      "metadata": {
        "id": "Y2ZUSnOwO3NW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd785a8-fc76-4fcc-f382-849da97a9662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neuroticism  :  35\n",
            "agreeableness  :  35\n",
            "extraversion  :  35\n",
            "conscientiousness  :  35\n",
            "openness  :  35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = path1+\"/train\"\n",
        "\n",
        "for cat in os.listdir(directory):\n",
        "  # print(cat)\n",
        "  num_files = 0\n",
        "  files = os.listdir(directory+'/'+cat)\n",
        "  print(cat,\" : \",len(files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akmGndmP65A_",
        "outputId": "a1385b6f-7ebe-44c4-d108-6496a76a078b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraversion  :  156\n",
            "neuroticism  :  116\n",
            "agreeableness  :  116\n",
            "openness  :  116\n",
            "conscientiousness  :  116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directories for training, validation, and testing data\n",
        "train_dir = path1+\"/train\"\n",
        "val_dir = path1+\"/val\"\n",
        "test_dir = path1+\"/test\"\n",
        "\n",
        "# Create the validation directory if it doesn't exist\n",
        "if not os.path.exists(val_dir):\n",
        "    os.mkdir(val_dir)\n",
        "\n",
        "# Get the list of subdirectories in the train directory\n",
        "subdirs = os.listdir(train_dir)\n",
        "\n",
        "# Loop over the subdirectories and move 20% of the images to the validation directory\n",
        "for subdir in subdirs:\n",
        "    subdir_path = os.path.join(train_dir, subdir)\n",
        "    val_subdir_path = os.path.join(val_dir, subdir)\n",
        "\n",
        "    # Create the validation subdirectory if it doesn't exist\n",
        "    if not os.path.exists(val_subdir_path):\n",
        "        os.mkdir(val_subdir_path)\n",
        "\n",
        "    # Get the list of image files in the subdirectory\n",
        "    files = os.listdir(subdir_path)\n",
        "\n",
        "    # Calculate the number of images to move to validation (20% of total)\n",
        "    n_val = int(len(files) * 0.2)\n",
        "\n",
        "    # Move the images to the validation directory\n",
        "    for i in range(n_val):\n",
        "        file = files[i]\n",
        "        src_path = os.path.join(subdir_path, file)\n",
        "        dst_path = os.path.join(val_subdir_path, file)\n",
        "        shutil.move(src_path, dst_path)\n"
      ],
      "metadata": {
        "id": "oCjBx_VGllKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = path1+\"/val\"\n",
        "\n",
        "for cat in os.listdir(directory):\n",
        "  # print(cat)\n",
        "  num_files = 0\n",
        "  files = os.listdir(directory+'/'+cat)\n",
        "  print(cat,\" : \",len(files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWCzVBn1lVje",
        "outputId": "5c5c5f8b-48cf-4898-e56a-20c7ce837443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extraversion  :  39\n",
            "neuroticism  :  29\n",
            "agreeableness  :  28\n",
            "openness  :  28\n",
            "conscientiousness  :  29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = '/content/drive/MyDrive/spectograpgh_train_test'\n",
        "\n",
        "# Define the image dimensions and number of classes\n",
        "img_width, img_height = 224, 224\n",
        "num_classes = 5"
      ],
      "metadata": {
        "id": "x7-uNhl56l8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the directories for training, validation, and testing data\n",
        "train_dir = path1+\"/train\"\n",
        "val_dir = path1+\"/val\"\n",
        "test_dir = path1+\"/test\"\n",
        "\n",
        "# Define the image data generators with normalization\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generate batches of images and labels for training, validation, and testing data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='training')\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        subset='validation')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oHUDAF768ul",
        "outputId": "eca947be-a59e-4d7a-ed79-c4ddb8fd7989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 497 images belonging to 5 classes.\n",
            "Found 123 images belonging to 5 classes.\n",
            "Found 175 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator.class_indices\n",
        "classes = { j:i for i,j in val_generator.class_indices.items()}\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ3sxpMJl3Aw",
        "outputId": "68cd5013-72f0-44da-e688-2871e547dbc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'agreeableness',\n",
              " 1: 'conscientiousness',\n",
              " 2: 'extraversion',\n",
              " 3: 'neuroticism',\n",
              " 4: 'openness'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "Hhm3e28slYPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(img_width, img_height,3)),\n",
        "        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.01)),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "o_YUYngO6hyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "CoBUJA-U6siy",
        "outputId": "54ff1df3-8943-46e3-e10c-0b4959f76290",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 224, 224, 64)     256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 112, 112, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 56, 56, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 200704)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               102760960 \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 103,912,773\n",
            "Trainable params: 103,910,853\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with appropriate loss and optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data and validate on the validation data\n",
        "model.fit(train_generator, epochs=20, validation_data=val_generator)\n",
        "\n",
        "# Evaluate the model on the testing data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BYSQuvL85Li",
        "outputId": "a83b6e26-edd3-4afa-ddda-f197f7a5d554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 8s 333ms/step - loss: 14.3481 - accuracy: 0.2334 - val_loss: 32.5975 - val_accuracy: 0.1870\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 5s 308ms/step - loss: 21.0838 - accuracy: 0.2817 - val_loss: 52.3765 - val_accuracy: 0.1870\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 5s 321ms/step - loss: 18.0241 - accuracy: 0.3581 - val_loss: 25.8132 - val_accuracy: 0.1545\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 5s 310ms/step - loss: 14.5001 - accuracy: 0.3340 - val_loss: 26.1243 - val_accuracy: 0.2439\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 12.2004 - accuracy: 0.3159 - val_loss: 49.0616 - val_accuracy: 0.2520\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 6s 336ms/step - loss: 10.1878 - accuracy: 0.3883 - val_loss: 95.5763 - val_accuracy: 0.2520\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 6s 344ms/step - loss: 8.8410 - accuracy: 0.3702 - val_loss: 97.9430 - val_accuracy: 0.2520\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 7.6913 - accuracy: 0.4869 - val_loss: 80.6311 - val_accuracy: 0.2520\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 6.6378 - accuracy: 0.5412 - val_loss: 55.7000 - val_accuracy: 0.2520\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 6s 348ms/step - loss: 5.9644 - accuracy: 0.5694 - val_loss: 34.2870 - val_accuracy: 0.2520\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 5.2317 - accuracy: 0.6660 - val_loss: 33.2784 - val_accuracy: 0.2520\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 6s 351ms/step - loss: 4.7969 - accuracy: 0.7404 - val_loss: 39.7807 - val_accuracy: 0.2520\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 5s 309ms/step - loss: 4.1736 - accuracy: 0.8612 - val_loss: 47.5227 - val_accuracy: 0.2520\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 4.0738 - accuracy: 0.8833 - val_loss: 52.1897 - val_accuracy: 0.2520\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 5s 306ms/step - loss: 3.9661 - accuracy: 0.9155 - val_loss: 23.6289 - val_accuracy: 0.2520\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 5s 319ms/step - loss: 3.8092 - accuracy: 0.9276 - val_loss: 22.5222 - val_accuracy: 0.1870\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 5s 307ms/step - loss: 3.5806 - accuracy: 0.9477 - val_loss: 17.0730 - val_accuracy: 0.1626\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 5s 303ms/step - loss: 3.2476 - accuracy: 0.9477 - val_loss: 17.5107 - val_accuracy: 0.2520\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 5s 322ms/step - loss: 3.0074 - accuracy: 0.9557 - val_loss: 28.2698 - val_accuracy: 0.2520\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 5s 305ms/step - loss: 3.4722 - accuracy: 0.9537 - val_loss: 60.9887 - val_accuracy: 0.2520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1aa8607e20>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "eUjZBzVenACa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy:', test_loss)"
      ],
      "metadata": {
        "id": "WlC07RrTg6rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a214e79d-1579-44b8-ed0c-22fcb45212d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.61104537342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/models/audio_model.h5\")"
      ],
      "metadata": {
        "id": "zD2PXnVBpRjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"/content/drive/MyDrive/models/audio_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "5h9WhC2S0rxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/models/audio_model.pkl\", \"rb\") as f:\n",
        "    pmodel = pickle.load(f)"
      ],
      "metadata": {
        "id": "9m8kV8yLmdfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import math\n",
        "class find_ans :\n",
        "  def __init__(self,model_name):\n",
        "    with open(model_name, \"rb\") as f:\n",
        "      self.model = pickle.load(f)\n",
        "    self.dic = {0: 'agreeableness',\n",
        "                1: 'conscientiousness',\n",
        "                2: 'extraversion',\n",
        "                3: 'neuroticism',\n",
        "                4: 'openness'}\n",
        "  def audio_to_spec(self,aud) :\n",
        "    signal, sr = librosa.load(aud, sr=22050)\n",
        "    size = signal.shape[0]\n",
        "    start = 0\n",
        "    print(\"Im at 1\")\n",
        "    end = start + math.floor(size/5)\n",
        "    for i in range(5):\n",
        "        part_of_signal = signal[start:end]\n",
        "        mfcc = librosa.feature.mfcc(y=part_of_signal,\n",
        "                    n_fft=2048,\n",
        "                    hop_length=512,\n",
        "                    n_mfcc=13)\n",
        "        librosa.display.specshow(mfcc, sr=sr, hop_length=512)\n",
        "        plt.savefig(f\"test_img_{i}.png\")\n",
        "        plt.axis('off')\n",
        "        plt.clf()\n",
        "        start = end\n",
        "        end = start + math.floor(size/5)\n",
        "  def predict(self,aud):\n",
        "    self.audio_to_spec(aud)\n",
        "    results = []\n",
        "    for i in range(5):\n",
        "      matrix = image.load_img(f\"test_img_{i}.png\",target_size=(200,200))\n",
        "      matrix = image.img_to_array(matrix)\n",
        "      pred = self._predict(matrix)\n",
        "      print(i)\n",
        "      results.append(pred)\n",
        "      # from collections import Counter\n",
        "      # return Counter(results).most_common()[0][0]\n",
        "    averaged_probs = np.mean(results, axis=0)\n",
        "    # print(averaged_probs)\n",
        "    dfinal={}\n",
        "    k=0\n",
        "    for j in self.dic.values():\n",
        "      dfinal[j]=averaged_probs[0][k]\n",
        "      k+=1\n",
        "    return dfinal\n",
        "  def _predict(self,specgram):\n",
        "    specgram = specgram/255.0\n",
        "    specgram = specgram.reshape(1,specgram.shape[0],specgram.shape[1],specgram.shape[2])\n",
        "    prediction = self.model.predict(specgram)\n",
        "    return prediction\n",
        "    # self.result.append(prediction)\n",
        "    # print(prediction)\n",
        "    # prediction = np.argmax(prediction)\n",
        "    # return self.dic[prediction]"
      ],
      "metadata": {
        "id": "-Z0YZDka7dpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = find_ans(\"/content/drive/MyDrive/models/image_model.pkl\")\n"
      ],
      "metadata": {
        "id": "w8oH_JlfmFgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj.predict(\"/content/drive/MyDrive/audio_train_test/test/extraversion/JIYZTruMpiI.003.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "bejzZ3FvninR",
        "outputId": "cc9b4689-87ce-4515-8892-88d87f934a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Im at 1\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "0\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "2\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'agreeableness': 0.015448401,\n",
              " 'conscientiousness': 0.10953869,\n",
              " 'extraversion': 0.033935584,\n",
              " 'neuroticism': 0.76170516,\n",
              " 'openness': 0.0793722}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tcx9-Hb3vMIQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}